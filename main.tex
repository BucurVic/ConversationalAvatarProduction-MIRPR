\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[romanian]{babel}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{setspace}
\geometry{margin=2.5cm}
\setstretch{1.2}

\begin{document}

\begin{center}
{\Large \textbf{BABEȘ-BOLYAI UNIVERSITY, CLUJ-NAPOCA, ROMANIA}}\\[0.2cm]
{\large FACULTY OF MATHEMATICS AND COMPUTER SCIENCE}\\[2cm]
{\Huge \textbf{Face2Learn}}\\[0.3cm]
{\Large -- MIRPR Report 2025 --}\\[2cm]

\textbf{Team members:}\\
Bucur Victor Sever, Popoviciu Luca, Porcar Cezar, Potra-Rațiu Darius, Preduca Matei\\[2cm]
2025
\end{center}

\newpage

\begin{abstract}
Aplicația reprezintă un sistem inteligent bazat pe inteligență artificială, denumit \textbf{Face2Learn}, care combină modele de limbaj mari (LLM), sinteză vocală (TTS) și animație facială pentru a crea o experiență de învățare naturală și interactivă. Scopul proiectului este de a transforma informațiile academice în explicații conversaționale, vizuale și auditive, crescând astfel implicarea, accesibilitatea și retenția informației. Performanța sistemului este evaluată prin acuratețea răspunsurilor, latența end-to-end și naturalețea percepută a avatarului.
\end{abstract}

\tableofcontents
\newpage

\chapter{Descrierea problemei rezolvate cu ajutorul AI}

\section{Contextul problemei}
Sistemele educaționale tradiționale se bazează predominant pe text și prelegeri statice. În contextul actual al digitalizării, apare nevoia de metode de predare interactive, personalizate și accesibile. Proiectul \textbf{Face2Learn} propune utilizarea inteligenței artificiale multimodale pentru a crea un asistent virtual care explică concepte academice prin vorbire și expresii faciale sincronizate.

Modelul AI poate înțelege întrebări formulate în limbaj natural, poate accesa informații relevante din materiale educaționale și poate furniza răspunsuri clare, exprimate vocal și vizual printr-un avatar animat.

\section{Scopul și importanța problemei}
Scopul principal este de a transforma procesul de învățare într-o experiență naturală, captivantă și accesibilă. Importanța proiectului derivă din:
\begin{itemize}
  \item creșterea \textbf{engagement-ului} și motivației elevilor/studenților;
  \item asigurarea \textbf{accesibilității} pentru persoane cu deficiențe de vedere sau auz;
  \item sprijinirea cadrelor didactice prin automatizarea explicațiilor și a sesiunilor de Q\&A;
  \item posibilitatea \textbf{învățării personalizate} în ritmul fiecărui utilizator.
\end{itemize}

\section{Utilizatorii sistemului}
\begin{itemize}
  \item \textbf{Studenți și elevi} – folosesc avatarul AI pentru explicații și recapitulări;
  \item \textbf{Profesori și tutori} – utilizează sistemul pentru demonstrații și asistență automată;
  \item \textbf{Instituții educaționale} – integrează soluția pentru suport didactic 24/7;
  \item \textbf{Persoane cu dizabilități} – beneficiază de conținut multimodal adaptat.
\end{itemize}

\section{Datele de intrare și ieșire}
\textbf{Date de intrare:}
\begin{itemize}
  \item întrebări formulate în limbaj natural (text sau voce);
  \item documente educaționale (manuale, cursuri, notițe);
  \item preferințe ale utilizatorului (limbă, voce, tonalitate).
\end{itemize}

\textbf{Date de ieșire:}
\begin{itemize}
  \item răspuns text generat de LLM;
  \item voce sintetică naturală generată prin TTS;
  \item videoclip animat cu avatar sincronizat cu vorbirea.
\end{itemize}

\section{Tipurile de date utilizate}
\begin{itemize}
  \item corpusuri textuale academice și explicații didactice;
  \item înregistrări audio pentru antrenarea TTS;
  \item imagini/video cu expresii faciale pentru sincronizare (lip-sync);
  \item embeddings semantice pentru căutare contextuală (RAG).
\end{itemize}

\section{Măsurarea performanței sistemului AI}
Performanța sistemului este evaluată prin indicatori cantitativi și calitativi:
\begin{itemize}
  \item \textbf{Acuratețea răspunsurilor} – procentul de răspunsuri corecte;
  \item \textbf{Timpul mediu de răspuns} – durata procesării end-to-end;
  \item \textbf{Calitatea animației} – gradul de sincronizare buze-vorbire;
  \item \textbf{Consum de resurse} – memorie și timp de inferență.
\end{itemize}

\chapter{Related work and useful tools and technologies}

Această secțiune prezintă zece proiecte și tehnologii relevante pentru construcția unui avatar AI educațional. Pentru fiecare sunt menționate tipul datelor folosite, algoritmii utilizați, performanțele și tehnologiile implicate.

\section{1. LoRA (Low-Rank Adaptation)}
Date: text educațional. \\
Algoritmi: fine-tuning eficient al LLM-urilor prin adaptare low-rank. \\
Performanță: îmbunătățire a acurateței cu cost redus. \\
Tehnologii: PyTorch, Hugging Face, GitHub open-source.

\section{2. QLoRA}
Date: corpus text. \\
Algoritmi: fine-tuning cu cuantizare pentru reducerea memoriei. \\
Performanță: menține calitatea modelului la 4-bit. \\
Tehnologii: Transformers, bitsandbytes, Hugging Face.

\section{3. llama.cpp}
Date: text. \\
Algoritmi: inferență locală pentru modele cuantizate. \\
Performanță: latență redusă pe CPU. \\
Tehnologii: C++, GGUF models, GitHub.

\section{4. TinyLLM (Phi, Mistral, TinyLLaMA)}
Date: text. \\
Algoritmi: modele compacte pentru rulare eficientă. \\
Performanță: raport bun între viteză și acuratețe. \\
Tehnologii: PyTorch, Hugging Face.

\section{5. RAGFlow}
Date: documente și note de curs. \\
Algoritmi: RAG (retrieval augmented generation). \\
Performanță: răspunsuri mai relevante. \\
Tehnologii: LangChain, FAISS, GitHub.

\section{6. RAG-Anything}
Date: fișiere locale (PDF, text). \\
Algoritmi: flux simplificat RAG. \\
Performanță: acces rapid la surse externe. \\
Tehnologii: Python, Streamlit, GitHub.

\section{7. Whisper TTS}
Date: corpusuri audio şi transcripţii text. \\
Algoritmi: model neural de sinteză vocală bazat pe arhitectura Whisper. \\
Performanţă: voce naturală şi suport multilingv. \\
Tehnologii: PyTorch, Whisper TTS API (OpenAI), Hugging Face, GitHub.

\section{8. Piper}
Date: audio/text. \\
Algoritmi: TTS optimizat pentru dispozitive edge. \\
Performanță: latență foarte mică. \\
Tehnologii: Rust, on-device inference.

\section{9. Wav2Lip}
Date: video + audio. \\
Algoritmi: lip-sync bazat pe rețele CNN. \\
Performanță: aliniere buze-vorbire realistă. \\
Tehnologii: PyTorch, OpenCV, GitHub.

\section{10. SadTalker}
Date: imagine + audio. \\
Algoritmi: talking-face generation dintr-o singură imagine. \\
Performanță: expresii faciale naturale. \\
Tehnologii: PyTorch, DeepFace, GitHub.

\chapter{Evaluarea sistemului RAG utilizat în Face2Learn}

\section{Descrierea și explorarea datelor (EDA)}
Pentru evaluarea componentei de \textbf{întrebare-răspuns} din sistemul Face2Learn, a fost creat manual un set de date format din \textbf{50 de perechi întrebare–răspuns}. Fiecare întrebare a fost extrasă din conținutul manualului \texttt{manual2022.pdf}, iar răspunsul aferent reprezintă transcrierea exactă a fragmentului relevant.

\textbf{Structura fișierului de date (\texttt{evaluare.json}):}
\begin{verbatim}
[
  {
    "intrebare": "Ce reprezintă un segment orientat?",
    "raspuns_asteptat": "un segment ... unde s-a precizat originea si extremitatea"
  },
  ...
]
\end{verbatim}

\textbf{Preprocesare:}
\begin{itemize}
  \item Eliminarea diacriticelor pentru uniformitate.
  \item Conversia la litere mici și eliminarea spațiilor multiple.
  \item Nu s-a aplicat tokenizare, deoarece evaluarea folosește similaritate semantică și ROUGE.
\end{itemize}

\textbf{Explorare sumară:}
\begin{itemize}
  \item Număr total de exemple: 100;
  \item Lungime medie întrebare: 9 cuvinte;
  \item Lungime medie răspuns: 12 cuvinte;
  \item Domeniu: concepte geometrice (vectori, segmente, egalitate etc.);
  \item Tip date: text scurt, conceptual – ideal pentru evaluarea unui sistem RAG.
\end{itemize}

\section{Descrierea algoritmului inteligent}
\textbf{Algoritm ales:} \textit{Retrieval-Augmented Generation (RAG)}.

\textbf{Motivație:}  
Arhitectura RAG combină avantajele modelelor de căutare contextuală (retrieval) cu cele de generare (generation), permițând sistemului să răspundă coerent pe baza unui context relevant extras dintr-o bază de cunoștințe (PDF-ul cursului).  
Această abordare elimină necesitatea antrenării unui model mare de la zero, reducând costurile și riscul de halucinații.

\textbf{Componente principale:}
\begin{itemize}
  \item \textbf{Retrieval:}  
  Model de embedding \texttt{thenlper/gte-small} (din \texttt{sentence-transformers}) și indexare cu \texttt{faiss-cpu}.  
  Scopul este transformarea fragmentelor PDF în vectori semantici și extragerea celor mai relevante pasaje.
  \item \textbf{Generation:}  
  Modelul \texttt{mistral-7b-instruct-v0.3.Q4\_K\_M.gguf}, rulat local prin LM Studio.  
  Acesta generează răspunsul final folosind contextul returnat de retriever.
\end{itemize}

\textbf{Librării utilizate:} \texttt{langchain}, \texttt{sentence-transformers}, \texttt{faiss-cpu}, \texttt{numpy}, \texttt{transformers}, \texttt{sklearn.metrics}.

\section{Metodologia experimentală}
\textbf{Împărțirea datelor:}  
Setul de 50 de exemple a fost folosit în întregime ca \textbf{set de test}.  
Scopul principal a fost evaluarea sistemului complet (RAG + LLM), nu antrenarea unui model nou.

\textbf{Hiperparametri utilizați:}

\begin{center}
\begin{tabular}{|l|c|p{6cm}|}
\hline
\textbf{Parametru} & \textbf{Valoare} & \textbf{Descriere} \\
\hline
chunk\_size & 256 & Lungimea unui fragment de text la indexare \\
\hline
chunk\_overlap & 25 & Suprapunerea dintre fragmente consecutive \\
\hline
k & 4 & Numărul de pasaje returnate de retriever \\
\hline
temperature & 0.3 & Controlul creativității LLM-ului \\
\hline
\end{tabular}
\end{center}

\textbf{Metrici de evaluare:}
\begin{itemize}
  \item \textbf{ROUGE-L (F1):} măsoară suprapunerea exactă între răspunsul generat și cel așteptat;
  \item \textbf{Similaritate Semantică (Cosine Similarity):} măsoară apropierea conceptuală dintre răspunsuri, folosind embedding-urile \texttt{gte-small}.
\end{itemize}

\section{Rezultate obținute}

\begin{center}
\begin{tabular}{|l|c|}
\hline
\textbf{Metrică} & \textbf{Valoare medie} \\
\hline
ROUGE-L (F1) & 20.61\% \\
\hline
Similaritate Semantică & 90.24\% \\
\hline
\end{tabular}
\end{center}

\textbf{Interpretare:}
\begin{itemize}
  \item Scorul semantic ridicat (≈90\%) indică faptul că sistemul a înțeles corect întrebările și a generat răspunsuri cu același sens;
  \item Scorul ROUGE redus (≈20\%) arată că modelul preferă să reformuleze textul în loc să reproducă exact pasajul original.
\end{itemize}

\textbf{Exemple reprezentative:}

\begin{center}
\begin{tabular}{|c|p{3.5cm}|p{4cm}|p{4cm}|p{3cm}|}
\hline
\textbf{Caz} & \textbf{Întrebare} & \textbf{Răspuns așteptat} & \textbf{Răspuns generat} & \textbf{Observație} \\
\hline
1 & Segment orientat & un segment ... cu origine și extremitate & o porțiune ... cu direcție asignată & sens corect, formulare diferită \\
\hline
2 & Egalitate segmente & A=C și B=D & A=D și B=C & halucinație (ordine inversată) \\
\hline
3 & Vector liber & o clasă de echivalență & o familie de vectori legați & parafrazare semantică \\
\hline
\end{tabular}
\end{center}

\section{Analiza finală}
Diferența semnificativă dintre scorurile ROUGE și Similaritate Semantică evidențiază o problemă frecventă în sistemele RAG:
\begin{itemize}
  \item Modelul LLM \textbf{înțelege contextul}, dar nu respectă instrucțiunea „răspunde exclusiv pe baza textului oferit”;
  \item Răspunsurile sunt logic corecte, dar lexical diferite;
  \item În unele cazuri apar \textbf{halucinații minore} (exemplul \#2).
\end{itemize}

\textbf{Concluzie parțială:}
Rezultatele arată că sistemul RAG implementat are o \textbf{performanță semantică excelentă}, dar necesită îmbunătățiri și aplicarea unei penalizări de diversitate în prompt.

\chapter*{Concluzii}
Proiectul „Face2Learn” oferă o abordare inovatoare de integrare a AI multimodal (text, voce, video) în domeniul educației. Combinația între LLM-uri optimizate, TTS și animație sincronizată contribuie la îmbunătățirea experienței de învățare, făcând-o mai naturală, mai interactivă și mai accesibilă.

\end{document}