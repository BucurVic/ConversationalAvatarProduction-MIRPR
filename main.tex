\documentclass[12pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[romanian]{babel}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{setspace}
\geometry{margin=2.5cm}
\setstretch{1.2}

\begin{document}

\begin{center}
{\Large \textbf{BABEȘ-BOLYAI UNIVERSITY, CLUJ-NAPOCA, ROMANIA}}\\[0.2cm]
{\large FACULTY OF MATHEMATICS AND COMPUTER SCIENCE}\\[2cm]
{\Huge \textbf{Face2Learn}}\\[0.3cm]
{\Large -- MIRPR Report 2025 --}\\[2cm]

\textbf{Team members:}\\
Bucur Victor Sever, Popoviciu Luca, Porcar Cezar, Potra-Rațiu Darius, Preduca Matei\\[2cm]
2025
\end{center}

\newpage

\begin{abstract}
Aplicația reprezintă un sistem inteligent bazat pe inteligență artificială, denumit \textbf{Face2Learn}, care combină modele de limbaj mari (LLM), sinteză vocală (TTS) și animație facială pentru a crea o experiență de învățare naturală și interactivă. Scopul proiectului este de a transforma informațiile academice în explicații conversaționale, vizuale și auditive, crescând astfel implicarea, accesibilitatea și retenția informației. Performanța sistemului este evaluată prin acuratețea răspunsurilor, latența end-to-end și naturalețea percepută a avatarului.
\end{abstract}

\tableofcontents
\newpage

\chapter{Descrierea problemei rezolvate cu ajutorul AI}

\section{Contextul problemei}
Sistemele educaționale tradiționale se bazează predominant pe text și prelegeri statice. În contextul actual al digitalizării, apare nevoia de metode de predare interactive, personalizate și accesibile. Proiectul \textbf{Face2Learn} propune utilizarea inteligenței artificiale multimodale pentru a crea un asistent virtual care explică concepte academice prin vorbire și expresii faciale sincronizate.

Modelul AI poate înțelege întrebări formulate în limbaj natural, poate accesa informații relevante din materiale educaționale și poate furniza răspunsuri clare, exprimate vocal și vizual printr-un avatar animat.

\section{Scopul și importanța problemei}
Scopul principal este de a transforma procesul de învățare într-o experiență naturală, captivantă și accesibilă. Importanța proiectului derivă din:
\begin{itemize}
  \item creșterea \textbf{engagement-ului} și motivației elevilor/studenților;
  \item asigurarea \textbf{accesibilității} pentru persoane cu deficiențe de vedere sau auz;
  \item sprijinirea cadrelor didactice prin automatizarea explicațiilor și a sesiunilor de Q\&A;
  \item posibilitatea \textbf{învățării personalizate} în ritmul fiecărui utilizator.
\end{itemize}

\section{Utilizatorii sistemului}
\begin{itemize}
  \item \textbf{Studenți și elevi} – folosesc avatarul AI pentru explicații și recapitulări;
  \item \textbf{Profesori și tutori} – utilizează sistemul pentru demonstrații și asistență automată;
  \item \textbf{Instituții educaționale} – integrează soluția pentru suport didactic 24/7;
  \item \textbf{Persoane cu dizabilități} – beneficiază de conținut multimodal adaptat.
\end{itemize}

\section{Datele de intrare și ieșire}
\textbf{Date de intrare:}
\begin{itemize}
  \item întrebări formulate în limbaj natural (text sau voce);
  \item documente educaționale (manuale, cursuri, notițe);
  \item preferințe ale utilizatorului (limbă, voce, tonalitate).
\end{itemize}

\textbf{Date de ieșire:}
\begin{itemize}
  \item răspuns text generat de LLM;
  \item voce sintetică naturală generată prin TTS;
  \item videoclip animat cu avatar sincronizat cu vorbirea.
\end{itemize}

\section{Tipurile de date utilizate}
\begin{itemize}
  \item corpusuri textuale academice și explicații didactice;
  \item înregistrări audio pentru antrenarea TTS;
  \item imagini/video cu expresii faciale pentru sincronizare (lip-sync);
  \item embeddings semantice pentru căutare contextuală (RAG).
\end{itemize}

\section{Măsurarea performanței sistemului AI}
Performanța sistemului este evaluată prin indicatori cantitativi și calitativi:
\begin{itemize}
  \item \textbf{Acuratețea răspunsurilor} – procentul de răspunsuri corecte;
  \item \textbf{Timpul mediu de răspuns} – durata procesării end-to-end;
  \item \textbf{Calitatea animației} – gradul de sincronizare buze-vorbire;
  \item \textbf{Consum de resurse} – memorie și timp de inferență.
\end{itemize}

\chapter{Related work and useful tools and technologies}

Această secțiune prezintă zece proiecte și tehnologii relevante pentru construcția unui avatar AI educațional. Pentru fiecare sunt menționate tipul datelor folosite, algoritmii utilizați, performanțele și tehnologiile implicate.

\section{1. LoRA (Low-Rank Adaptation)}
Date: text educațional. \\
Algoritmi: fine-tuning eficient al LLM-urilor prin adaptare low-rank. \\
Performanță: îmbunătățire a acurateței cu cost redus. \\
Tehnologii: PyTorch, Hugging Face, GitHub open-source.

\section{2. QLoRA}
Date: corpus text. \\
Algoritmi: fine-tuning cu cuantizare pentru reducerea memoriei. \\
Performanță: menține calitatea modelului la 4-bit. \\
Tehnologii: Transformers, bitsandbytes, Hugging Face.

\section{3. llama.cpp}
Date: text. \\
Algoritmi: inferență locală pentru modele cuantizate. \\
Performanță: latență redusă pe CPU. \\
Tehnologii: C++, GGUF models, GitHub.

\section{4. TinyLLM (Phi, Mistral, TinyLLaMA)}
Date: text. \\
Algoritmi: modele compacte pentru rulare eficientă. \\
Performanță: raport bun între viteză și acuratețe. \\
Tehnologii: PyTorch, Hugging Face.

\section{5. RAGFlow}
Date: documente și note de curs. \\
Algoritmi: RAG (retrieval augmented generation). \\
Performanță: răspunsuri mai relevante. \\
Tehnologii: LangChain, FAISS, GitHub.

\section{6. RAG-Anything}
Date: fișiere locale (PDF, text). \\
Algoritmi: flux simplificat RAG. \\
Performanță: acces rapid la surse externe. \\
Tehnologii: Python, Streamlit, GitHub.

\section{7. Whisper TTS}
Date: corpusuri audio şi transcripţii text. \\
Algoritmi: model neural de sinteză vocală bazat pe arhitectura Whisper. \\
Performanţă: voce naturală şi suport multilingv. \\
Tehnologii: PyTorch, Whisper TTS API (OpenAI), Hugging Face, GitHub.

\section{8. Piper}
Date: audio/text. \\
Algoritmi: TTS optimizat pentru dispozitive edge. \\
Performanță: latență foarte mică. \\
Tehnologii: Rust, on-device inference.

\section{9. Wav2Lip}
Date: video + audio. \\
Algoritmi: lip-sync bazat pe rețele CNN. \\
Performanță: aliniere buze-vorbire realistă. \\
Tehnologii: PyTorch, OpenCV, GitHub.

\section{10. SadTalker}
Date: imagine + audio. \\
Algoritmi: talking-face generation dintr-o singură imagine. \\
Performanță: expresii faciale naturale. \\
Tehnologii: PyTorch, DeepFace, GitHub.

\chapter*{Concluzii}
Proiectul „Face2Learn” oferă o abordare inovatoare de integrare a AI multimodal (text, voce, video) în domeniul educației. Combinația între LLM-uri optimizate, TTS și animație sincronizată contribuie la îmbunătățirea experienței de învățare, făcând-o mai naturală, mai interactivă și mai accesibilă.

\end{document}
